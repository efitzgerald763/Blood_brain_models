{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu0kyaSF8MLQyWdFIIF+bk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efitzgerald763/Blood_brain_models/blob/Optimize_tree_models/XGBoost_Gradient_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connects to your Google Drive so you can import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/Blood_brain_pred/ENSG00000096060_blood_brain.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Set the index to the first column\n",
        "data.set_index(data.columns[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKe3Fn9nRRq",
        "outputId": "d5a97dbb-8960-4ce2-8264-9f0b9ee35cc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Transpose the dataframe so each gene is a feature and each sample is a column\n",
        "data_transposed = data.T\n",
        "\n",
        "data_transposed.sample(4)\n",
        "\n",
        "# Separate the target variable\n",
        "target_row = 'ENSG00000096060'\n",
        "y = data_transposed[target_row]\n",
        "X = data_transposed.drop(columns=[target_row])\n",
        "\n",
        "# Check the shapes to ensure they are as expected\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rg4vNIbnZiX",
        "outputId": "9cb2fb23-452b-4a04-91a2-3bb3f9651e27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81, 18706)\n",
            "(81,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "52-8bCzyh6AB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a6213f-3a4e-43ec-e464-9c895c15884d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Best Score for Gradient Boosting: -0.5824742788899331\n",
            "Mean Squared Error for Gradient Boosting: 0.398871261892831\n",
            "R-squared for Gradient Boosting: 0.26343537990002686\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define the parameter grid for Gradient Boosting\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100],\n",
        "    'learning_rate': [0.001, 0.01],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "# Initialize Gradient Boosting model\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Perform Grid Search for Gradient Boosting\n",
        "grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and score for Gradient Boosting\n",
        "print(f'Best Parameters for Gradient Boosting: {grid_search_gb.best_params_}')\n",
        "print(f'Best Score for Gradient Boosting: {grid_search_gb.best_score_}')\n",
        "\n",
        "# Use the best estimator to predict and evaluate for Gradient Boosting\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "y_pred_gb = best_gb.predict(X_test)\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "print(f'Mean Squared Error for Gradient Boosting: {mse_gb}')\n",
        "print(f'R-squared for Gradient Boosting: {r2_gb}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define the parameter grid for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "\n",
        "# Perform Grid Search for XGBoost\n",
        "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and score for XGBoost\n",
        "print(f'Best Parameters for XGBoost: {grid_search_xgb.best_params_}')\n",
        "print(f'Best Score for XGBoost: {grid_search_xgb.best_score_}')\n",
        "\n",
        "# Use the best estimator to predict and evaluate for XGBoost\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(f'Mean Squared Error for XGBoost: {mse_xgb}')\n",
        "print(f'R-squared for XGBoost: {r2_xgb}')\n"
      ],
      "metadata": {
        "id": "TMZb8LCKiYdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 1: Tune max_depth and min_child_weight\n",
        "param_grid_1 = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5]\n",
        "}\n",
        "\n",
        "xgb_model_1 = xgb.XGBRegressor(learning_rate=0.1, n_estimators=50, random_state=42)\n",
        "grid_search_1 = GridSearchCV(estimator=xgb_model_1, param_grid=param_grid_1, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "grid_search_1.fit(X_train, y_train)\n",
        "\n",
        "best_params_1 = grid_search_1.best_params_\n",
        "print(f'Best Parameters for Group 1: {best_params_1}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuhv7y-e5n7o",
        "outputId": "6b9962e0-acbf-4b18-d191-35417b9a9326"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Group 1: {'max_depth': 3, 'min_child_weight': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tune subsample and colsample_bytree\n",
        "param_grid_2 = {\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb_model_2 = xgb.XGBRegressor(\n",
        "    learning_rate=0.1, n_estimators=50,\n",
        "    max_depth=best_params_1['max_depth'],\n",
        "    min_child_weight=best_params_1['min_child_weight'],\n",
        "    random_state=42\n",
        ")\n",
        "grid_search_2 = GridSearchCV(estimator=xgb_model_2, param_grid=param_grid_2, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "grid_search_2.fit(X_train, y_train)\n",
        "\n",
        "best_params_2 = grid_search_2.best_params_\n",
        "print(f'Best Parameters for Group 2: {best_params_2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJkGEI9w8r2v",
        "outputId": "563b2e09-e21a-49d3-f59d-efe336fe8a5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Group 2: {'colsample_bytree': 0.8, 'subsample': 0.6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Tune learning_rate and n_estimators\n",
        "param_grid_3 = {\n",
        "    'learning_rate': [0.01, 0.05],\n",
        "    'n_estimators': [50, 100, 150]\n",
        "}\n",
        "\n",
        "xgb_model_3 = xgb.XGBRegressor(\n",
        "    max_depth=best_params_1['max_depth'],\n",
        "    min_child_weight=best_params_1['min_child_weight'],\n",
        "    subsample=best_params_2['subsample'],\n",
        "    colsample_bytree=best_params_2['colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "grid_search_3 = GridSearchCV(estimator=xgb_model_3, param_grid=param_grid_3, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "grid_search_3.fit(X_train, y_train)\n",
        "\n",
        "best_params_3 = grid_search_3.best_params_\n",
        "print(f'Best Parameters for Group 3: {best_params_3}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AoXyeVR8xlC",
        "outputId": "894b86b8-26b9-4fde-feee-3d07af2c3a25"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Group 3: {'learning_rate': 0.05, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_xgb_model = xgb.XGBRegressor(\n",
        "    max_depth=best_params_1['max_depth'],\n",
        "    min_child_weight=best_params_1['min_child_weight'],\n",
        "    subsample=best_params_2['subsample'],\n",
        "    colsample_bytree=best_params_2['colsample_bytree'],\n",
        "    learning_rate=best_params_3['learning_rate'],\n",
        "    n_estimators=best_params_3['n_estimators'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "final_xgb_model.fit(X_train, y_train)\n",
        "y_pred = final_xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate final model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Final Model MSE: {mse}')\n",
        "print(f'Final Model R-squared: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE723xgt80aO",
        "outputId": "3318f403-2f5a-4747-b233-596c0e6edd50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model MSE: 0.43788071007247586\n",
            "Final Model R-squared: 0.1913996577915995\n"
          ]
        }
      ]
    }
  ]
}